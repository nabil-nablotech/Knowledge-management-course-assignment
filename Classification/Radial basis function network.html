<!DOCTYPE html>
<html>
    <head>
        <title>Classification- Radial basis function network</title>
        <link rel="stylesheet" href="../style.css">
    </head>
    <body>
        <div id="header">
            <ul>
                <li ><a href="../home.html">Home</a></li>
                <li class="dropdown" >Description
                    <div class="dropmenu">
                        <span class="sidedropdown">Graphical Methods &#8250;
                            <div class="sidemenu">
                                <a href="../description/run chart.html"><span>Run charts</span></a>
                                <a href="../description/order chart.html"><span>Order charts</span></a>
                                <a href="../description/special chart.html"><span>Special charts</span></a>
                            </div>
                        </span>
                        <span class="sidedropdown">Statistical Methods &#8250;
                            <div class="sidemenu">
                                <a href="../description/hypothesis testing.html"><span>Hypothesis testing</span></a>
                                <a href="../description/coorelation.html"><span>Coorelation data</span></a>
                                <a href="../description/multi corelation data.html"><span>Multi corelation data</span></a>
                            </div>
                        </span>
                        <a href="../description/exploratory data analysis.html"><span>Exploratory Data Analysis</span></a>
                    </div>
                </li>

                <li class="dropdown" style="background-color: #30475e;">Classification
                    <div class="dropmenu">
                        <span class="sidedropdown">Logic based algorithim &#8250;
                            <div class="sidemenu">
                                <a href="../Classification/decision tree.html"><span>Decision trees</span></a>
                                <a href="../Classification/learning set of rules.html"><span>Learning set of rules</span></a>
                            </div>
                        </span>
                        <span class="sidedropdown">Perception based learners &#8250;
                            <div class="sidemenu">
                                <a href="../Classification/single layered perception.html"><span>Single layered perception</span></a>
                                <a href="../Classification/Multi layered perception.html"><span>Multi layered perception</span></a>
                                <a href="../Classification/Radial basis function network.html"><span>Radial basis function networks</span></a>
                            </div>
                        </span>
                        <span class="sidedropdown">Statistical learners &#8250;
                            <div class="sidemenu">
                                <a href="../Classification/naive bayes classifier.html"><span>Naive Bayes classifier</span></a>
                                <a href="../Classification/bayesian network.html"><span>Bayesian networks</span></a>
                            </div>
                        </span>
                        <span class="sidedropdown">Instance-based learners &#8250;
                            <div class="sidemenu">
                                <a href="../Classification/k-nearest.html"><span>k-nearest neighbours</span></a>
                            </div>
                        </span>
                        <a href="../Classification/simple vector machine.html"><span>Support Vector Machines</span></a>
                    </div>
                </li>

                <li class="dropdown">Regression
                    <div class="dropmenu">
                        <a href="#"><span >Linear regression</span></a>
                        <a href="#"><span >Polynomial regression</span></a>
                        <a href="#"><span >Multiple linear regression</span></a>
                        <span class="sidedropdown">Generalized linear models &#8250;
                            <div class="sidemenu">
                                <a href="#"><span>Logic regression</span></a>
                                <a href="#"><span>Poisson regression</span></a>
                            </div>
                        </span>
                        <a href="#"><span >Log-linear models</span></a>
                        <a href="#"><span >Regression trees</span></a>
                        <a href="#"><span >Instance-based regression</span></a>
                        <a href="#"><span>Multivariate adaptive regression splines</span></a>
                        <a href="#"><span>Support Vector Machines</span></a>
                        <a href="#"><span >Neural networks</span></a>
                    </div>
                </li>

                <li class="dropdown">Clustering
                    <div class="dropmenu">
                        <span class="sidedropdown">Hierarchical methods &#8250;
                            <div class="sidemenu">
                                <a href="#"><span>Agglomerative</span></a>
                                <a href="#"><span>Divisive</span></a>
                            </div>
                        </span>
                        <span class="sidedropdown">Partitioning methods &#8250;
                            <div class="sidemenu">
                                <a href="#"><span>K-Means</span></a>
                                <a href="#"><span>K-Medoids</span></a>
                            </div>
                        </span>
                        <span class="sidedropdown">Density-based methods &#8250;
                            <div class="sidemenu">
                                <a href="#"><span>DBSCAN</span></a>
                                <a href="#"><span>OPTICS</span></a>
                                <a href="#"><span>DENCLUE</span></a>
                            </div>
                        </span>
                        <span class="sidedropdown">Grid-based methods &#8250;
                            <div class="sidemenu">
                                <a href="#"><span>STING</span></a>
                                <a href="#"><span>WaveCluster</span></a>
                                <a href="#"><span>CLIQUE</span></a>
                            </div>
                        </span>
                        <span class="sidedropdown">Model base methods &#8250;
                            <div class="sidemenu">
                                <a href="#"><span>EM method</span></a>
                                <a href="#"><span>Conceptual Clustering</span></a>
                                <a href="#"><span>Neural networks</span></a>
                            </div>
                        </span>
                    </div>
                </li>

                <li class="dropdown">Association
                    <div class="dropmenu">
                        <a href="#"><span >Apriori algorithim</span></a>
                        <a href="#"><span >FP-Growth algorithim</span></a>
                        <a href="#"><span >Dynamic Hashing and Pruning</span></a>
                        <a href="#"><span >Partition algorithim</span></a>
                        <a href="#"><span >Sampling based algorithim</span></a>
                        <a href="#"><span >Dynamic Itemset</span></a>
                        <a href="#"><span >Counting tree-projection</span></a>
                    </div>
                </li>
                
            </ul>
        </div>
        <div id="content">
            <h1>Radial basis function network (RBNN)</h1>
            <p style="font-size: 12px;">Classification / Perception based learners / Radial basis function network</p>
            
            <br>

           <p>
               <img src="Radial basis function network.JPG" alt="radial">
           </p>
           <p>
            In Single Perceptron / Multi-layer Perceptron(MLP), we only have linear separability because they are composed of input and output layers(some hidden layers in MLP)
           </p>
           <p>
            For example, AND, OR functions are linearly-separable & XOR function is not linearly separable.
           </p>
           <p>
               <img src="Radial basis function network2.JPG" alt="radial">
           </p>
           <p>
            We atleast need one hidden layer to derive a non-linearity separation.
           </p>
           <p>
            Our RBNN what it does is, it transforms the input signal into another form, which can be then feed into the network to get linear separability.
           </p>
           <p>
            RBNN is structurally same as perceptron(MLP).
           </p>
           <p>
               <img src="Radial basis function network3.JPG" alt="radial">
           </p>
           <p>
            RBNN is composed of input, hidden, and output layer. RBNN is strictly limited to have exactly one hidden layer. We call this hidden layer as feature vector.
           </p>
           <p>
            RBNN increases dimenion of feature vector.
           </p>
           <p>
               <img src="Radial basis function network4.JPG" alt="">
           </p>
           <p>
            We apply non-linear transfer function to the feature vector before we go for classification problem.
           </p>
           <p>
            When we increase the dimension of the feature vector, the linear separability of feature vector increases.
           </p>
           <p>
            A non-linearity separable problem(pattern classification problem) is highly separable in high dimensional space than it is in low dimensional space.
            <br>[Cover’s Theorem]
           </p>
           <p>
            What is a Radial Basis Function ?
           </p>
           <p>We define a receptor = t</p>
           <p>We draw confrontal maps around the receptor.</p>
           <p>Gaussian Functions are generally used for Radian Basis Function(confrontal mapping). So we define the radial distance r = ||x- t||.</p>
           <p>
               <img src="Radial basis function network5.JPG" alt="rad">
           </p>
           <p>
               <img src="Radial basis function network6.JPG" alt="">
           </p>

           <h4>Example. XOR function :-</h4>
           <p>
            I have 4 inputs and I will not increase dimension at the feature vector here. So I will select 2 receptors here. For each transformation function ϕ(x), we will have each receptors t.
           </p>
           <p>
            Now consider the RBNN architecture,
           </p>
           <p>P := # of input features/ values.</p>
           <p> M = # of transformed vector dimensions (hidden layer width). So M ≥ P usually be.</p>
           <p>Each node in the hidden layer, performs a set of non-linear radian basis function.</p>
           <p>Output C will remains the same as for the classification problems(certain number of class labels as predefined).  </p>
           <p>
               <img src="Radial basis function network7.JPG" alt="">
           </p>
            <p>
                <img src="Radial basis function network8.JPG" alt="">
            </p>
            <p>
                <img src="Radial basis function network9.JPG" alt="">
            </p>
            <p>Only Nodes in the hidden layer perform the radian basis transformation function.</p>
            <p>Output layer performs the linear combination of the outputs of the hidden layer to give a final probabilistic value at the output layer.</p>
            <p>So the classification is only done only @ (hidden layer → output layer)</p>
            <h4>Training the RBNN :-</h4>
            <p>First, we should train the hidden layer using back propagation.</p>
            <p>Neural Network training(back propagation) is a curve fitting method. It fits a non-linear curve during the training phase. It runs through stochastic approximation, which we call the back propagation.</p>
            <p>For each of the node in the hidden layer, we have to find t(receptors) & the variance (σ)[variance — the spread of the radial basis function]</p>
            <p>On the second training phase, we have to update the weighting vectors between hidden layers & output layers.</p>
            <p> In hidden layers, each node represents each transformation basis function. Any of the function could satisfy the non-linear separability OR even combination of set of functions could satisfy the non-linear separability.</p>
            <p>So in our hidden layer transformation, all the non-linearity terms are included. Say like X² + Y² + 5XY ; its all included in a hyper-surface equation(X & Y are inputs).</p>
            <p>Therefore, the first stage of training is done by clustering algorithm. We define the number of cluster centers we need. And by clustering algorithm, we compute the cluster centers, which then is assigned as the receptors for each hidden neurons.</p>
            <p>I have to cluster N samples or observations into M clusters (N > M)</p>
            <p>So the output “clusters” are the “receptors”.</p>
            <p>for each receptors, I can find the variance as “the squared sum of the distances between the respective receptor & the each cluster nearest samples” := 1/N * ||X — t||²</p>
            <p>The interpretation of the first training phase is that the “feature vector is projected onto the transformed space”.</p>
            <p>
                <img src="Radial basis function network10.JPG" alt="">
            </p>

            <h4>Advantages of using RBNN than the MLP :-</h4>
            <ol>
                <li>Training in RBNN is faster than in Multi-layer Perceptron (MLP) → takes many interactions in MLP.</li>
                <li>We can easily interpret what is the meaning / function of the each node in hidden layer of the RBNN. This is difficult in MLP.</li>
                <li>(what should be the # of nodes in hidden layer & the # of hidden layers) this parameterization is difficult in MLP. But this is not found in RBNN.</li>
                <li>Classification will take more time in RBNN than MLP.</li>
            </ol>

        </div>
        <div id="footer">
            Made with <span style="color: rgb(243, 52, 148);"> &#10084; </span> by IS third year students.
        </div>
    </body>
</html>