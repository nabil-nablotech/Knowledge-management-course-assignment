<!DOCTYPE html>
<html>
    <head>
        <title>Classification- Support Vector Machine</title>
        <link rel="stylesheet" href="../style.css">
    </head>
    <body>
        <div id="header">
            <ul>
                <li ><a href="../home.html">Home</a></li>
                <li class="dropdown" >Description
                    <div class="dropmenu">
                        <span class="sidedropdown">Graphical Methods &#8250;
                            <div class="sidemenu">
                                <a href="../description/run chart.html"><span>Run charts</span></a>
                                <a href="../description/order chart.html"><span>Order charts</span></a>
                                <a href="../description/special chart.html"><span>Special charts</span></a>
                            </div>
                        </span>
                        <span class="sidedropdown">Statistical Methods &#8250;
                            <div class="sidemenu">
                                <a href="../description/hypothesis testing.html"><span>Hypothesis testing</span></a>
                                <a href="../description/coorelation.html"><span>Coorelation data</span></a>
                                <a href="../description/multi corelation data.html"><span>Multi corelation data</span></a>
                            </div>
                        </span>
                        <a href="../description/exploratory data analysis.html"><span>Exploratory Data Analysis</span></a>
                    </div>
                </li>

                <li class="dropdown" style="background-color: #30475e;">Classification
                    <div class="dropmenu">
                        <span class="sidedropdown">Logic based algorithim &#8250;
                            <div class="sidemenu">
                                <a href="../Classification/decision tree.html"><span>Decision trees</span></a>
                                <a href="../Classification/learning set of rules.html"><span>Learning set of rules</span></a>
                            </div>
                        </span>
                        <span class="sidedropdown">Perception based learners &#8250;
                            <div class="sidemenu">
                                <a href="../Classification/single layered perception.html"><span>Single layered perception</span></a>
                                <a href="../Classification/Multi layered perception.html"><span>Multi layered perception</span></a>
                                <a href="../Classification/Radial basis function network.html"><span>Radial basis function networks</span></a>
                            </div>
                        </span>
                        <span class="sidedropdown">Statistical learners &#8250;
                            <div class="sidemenu">
                                <a href="../Classification/naive bayes classifier.html"><span>Naive Bayes classifier</span></a>
                                <a href="../Classification/bayesian network.html"><span>Bayesian networks</span></a>
                            </div>
                        </span>
                        <span class="sidedropdown">Instance-based learners &#8250;
                            <div class="sidemenu">
                                <a href="../Classification/k-nearest.html"><span>k-nearest neighbours</span></a>
                            </div>
                        </span>
                        <a href="../Classification/simple vector machine.html"><span>Support Vector Machines</span></a>
                    </div>
                </li>

                <li class="dropdown">Regression
                    <div class="dropmenu">
                        <a href="#"><span >Linear regression</span></a>
                        <a href="#"><span >Polynomial regression</span></a>
                        <a href="#"><span >Multiple linear regression</span></a>
                        <span class="sidedropdown">Generalized linear models &#8250;
                            <div class="sidemenu">
                                <a href="#"><span>Logic regression</span></a>
                                <a href="#"><span>Poisson regression</span></a>
                            </div>
                        </span>
                        <a href="#"><span >Log-linear models</span></a>
                        <a href="#"><span >Regression trees</span></a>
                        <a href="#"><span >Instance-based regression</span></a>
                        <a href="#"><span>Multivariate adaptive regression splines</span></a>
                        <a href="#"><span>Support Vector Machines</span></a>
                        <a href="#"><span >Neural networks</span></a>
                    </div>
                </li>

                <li class="dropdown">Clustering
                    <div class="dropmenu">
                        <span class="sidedropdown">Hierarchical methods &#8250;
                            <div class="sidemenu">
                                <a href="#"><span>Agglomerative</span></a>
                                <a href="#"><span>Divisive</span></a>
                            </div>
                        </span>
                        <span class="sidedropdown">Partitioning methods &#8250;
                            <div class="sidemenu">
                                <a href="#"><span>K-Means</span></a>
                                <a href="#"><span>K-Medoids</span></a>
                            </div>
                        </span>
                        <span class="sidedropdown">Density-based methods &#8250;
                            <div class="sidemenu">
                                <a href="#"><span>DBSCAN</span></a>
                                <a href="#"><span>OPTICS</span></a>
                                <a href="#"><span>DENCLUE</span></a>
                            </div>
                        </span>
                        <span class="sidedropdown">Grid-based methods &#8250;
                            <div class="sidemenu">
                                <a href="#"><span>STING</span></a>
                                <a href="#"><span>WaveCluster</span></a>
                                <a href="#"><span>CLIQUE</span></a>
                            </div>
                        </span>
                        <span class="sidedropdown">Model base methods &#8250;
                            <div class="sidemenu">
                                <a href="#"><span>EM method</span></a>
                                <a href="#"><span>Conceptual Clustering</span></a>
                                <a href="#"><span>Neural networks</span></a>
                            </div>
                        </span>
                    </div>
                </li>

                <li class="dropdown">Association
                    <div class="dropmenu">
                        <a href="#"><span >Apriori algorithim</span></a>
                        <a href="#"><span >FP-Growth algorithim</span></a>
                        <a href="#"><span >Dynamic Hashing and Pruning</span></a>
                        <a href="#"><span >Partition algorithim</span></a>
                        <a href="#"><span >Sampling based algorithim</span></a>
                        <a href="#"><span >Dynamic Itemset</span></a>
                        <a href="#"><span >Counting tree-projection</span></a>
                    </div>
                </li>
                
            </ul>
        </div>
        <div id="content">
            <h1>Support Vector Machine</h1>
            <p style="font-size: 12px;">Classification / Support Vector Machine</p>
            
            <br>

            <p>
                I guess by now you would’ve accustomed yourself with linear regression and logistic regression algorithms. If not, I suggest you have a look at them before moving on to support vector machine. Support vector machine is another simple algorithm that every machine learning expert should have in his/her arsenal. Support vector machine is highly preferred by many as it produces significant accuracy with less computation power. Support Vector Machine, abbreviated as SVM can be used for both regression and classification tasks. But, it is widely used in classification objectives.
            </p>
            <p>
                The objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space(N — the number of features) that distinctly classifies the data points.
            </p>
            <p>
                <img src="simple vector machine.JPG" alt="" width="1000px">
            </p>
            <p>
                To separate the two classes of data points, there are many possible hyperplanes that could be chosen. Our objective is to find a plane that has the maximum margin, i.e the maximum distance between data points of both classes. Maximizing the margin distance provides some reinforcement so that future data points can be classified with more confidence.
            </p>
            <h4>Hyperplanes and Support Vectors</h4>
            <p>
                <img src="simple vector machine2.JPG" alt="">
            </p>
            <p>
                Hyperplanes are decision boundaries that help classify the data points. Data points falling on either side of the hyperplane can be attributed to different classes. Also, the dimension of the hyperplane depends upon the number of features. If the number of input features is 2, then the hyperplane is just a line. If the number of input features is 3, then the hyperplane becomes a two-dimensional plane. It becomes difficult to imagine when the number of features exceeds 3.
            </p>
            <p>
                <img src="simple vector machine3.JPG" alt="">
            </p>
            <p>
                Support vectors are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane. Using these support vectors, we maximize the margin of the classifier. Deleting the support vectors will change the position of the hyperplane. These are the points that help us build our SVM.
            </p>
            <h4>Large Margin Intuition</h4>
            <p>
                In logistic regression, we take the output of the linear function and squash the value within the range of [0,1] using the sigmoid function. If the squashed value is greater than a threshold value(0.5) we assign it a label 1, else we assign it a label 0. In SVM, we take the output of the linear function and if that output is greater than 1, we identify it with one class and if the output is -1, we identify is with another class. Since the threshold values are changed to 1 and -1 in SVM, we obtain this reinforcement range of values([-1,1]) which acts as margin.
            </p>
            <h4>Cost Function and Gradient Updates</h4>
            <p>
                In the SVM algorithm, we are looking to maximize the margin between the data points and the hyperplane. The loss function that helps maximize the margin is hinge loss.
            </p>
            <p>
                <img src="simple vector machine4.JPG" alt="" width="1000px">
            </p>
            <p>
                The cost is 0 if the predicted value and the actual value are of the same sign. If they are not, we then calculate the loss value. We also add a regularization parameter the cost function. The objective of the regularization parameter is to balance the margin maximization and loss. After adding the regularization parameter, the cost functions looks as below.
            </p>
            <p>
                <img src="simple vector machine5.JPG" alt="">
            </p>
            <p>
                Now that we have the loss function, we take partial derivatives with respect to the weights to find the gradients. Using the gradients, we can update our weights.
            </p>
            <p>
                <img src="simple vector machine6.JPG" alt="">
            </p>
            <p>
                When there is no misclassification, i.e our model correctly predicts the class of our data point, we only have to update the gradient from the regularization parameter.
            </p>
            <p>
                <img src="simple vector machine7.JPG" alt="">
            </p>
            <p>
                When there is a misclassification, i.e our model make a mistake on the prediction of the class of our data point, we include the loss along with the regularization parameter to perform gradient update.
            </p>
            <p>
                <img src="simple vector machine8.JPG" alt="">
            </p>
            <h4>Conclusion</h4>
            <p>
                Support vector machine is an elegant and powerful algorithm. Use it wisely :)
            </p>
        </div>
        <div id="footer">
            Made with <span style="color: rgb(243, 52, 148);"> &#10084; </span> by IS third year students.
        </div>
    </body>
</html>